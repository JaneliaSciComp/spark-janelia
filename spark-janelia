#!/usr/bin/env python

import os
import sys
import argparse
import subprocess
import time
import multiprocessing
import traceback
from distutils import spawn

#########Variables to change for cluster environment
default_node_slots = 32
default_options = "-q spark-drivers"
alt_slots = 32
alt_options = ""
nonfull_options = "-R\"affinity[core(1)]\""
queue = 'spark32'
defaultversion = 'current'
default_runlimit = '8:00'
####################################################

def getmasterbyjobID(jobID):
    masterhost = None
    bjobsout = subprocess.check_output("bjobs -Xr -noheader -J master -o \"JOBID EXEC_HOST\" 2> /dev/null", universal_newlines=True, shell=True)
    masters = bjobsout.splitlines()

    bjobsoutu = subprocess.check_output("bjobs -Xr -noheader -app sparkbatch32 -o \"JOBID EXEC_HOST\" 2> /dev/null", universal_newlines=True, shell=True)
    for outline in bjobsoutu.splitlines():
        outlist = outline.split(' ')
        masteruhost = outlist[1].split(':')[0] 
        listelement = "{} {}".format(outlist[0], masteruhost)
        masters.append(listelement)
    for master in masters:
        if str(jobID) in master.split()[0]:
            masterhost = getmastername(master.split()[1])
            print(masterhost)
    return masterhost

def getmastername(master):
    if '*' in master:
        print('master has a *')
        masterhost = master.split('*')[1]; 
    else:
        masterhost = master 
    return masterhost


def getallmasters():
    masters = []
    #get normal masters
    command = "bjobs -X -noheader -J master -o \"JOBID STAT EXEC_HOST\" 2> /dev/null"
    bjobsout = subprocess.check_output(command, universal_newlines=True, shell=True)
    for outline in bjobsout.splitlines():
        outline = outline.split()
        masterhost = getmastername(outline[2])
        masterdict = {'jobid':outline[0], 'status':outline[1], 'host':masterhost}
        masters.append(masterdict)
    #get unified masters
    command = "bjobs -X -noheader -app sparkbatch32 -o \"JOBID STAT EXEC_HOST\" 2> /dev/null"
    bjobsout = subprocess.check_output(command, universal_newlines=True, shell=True)
    for outline in bjobsout.splitlines():
        outline = outline.split()
        masterhost = outline[2].split(':')[0]
        masterdict = {'jobid':outline[0], 'status':outline[1], 'host':masterhost.split('*')[1]}
        masters.append(masterdict)
    return masters

def getworkersbymasterID(masterID):
    workers = []
    command = "bjobs -X -noheader -J W{} -o \"JOBID STAT EXEC_HOST\" 2> /dev/null".format(masterID)
    bjobsout = subprocess.check_output(command, universal_newlines=True, shell=True)
    for outline in bjobsout.splitlines():
        outline = outline.split()
        workerdict = {'jobid':outline[0], 'status':outline[1], 'host':outline[2][3:]}
        workers.append(workerdict)
    return workers

def getdriversbymasterID(masterID):
    drivers = []
    command = "bjobs -X -noheader -J D{} -o \"JOBID STAT EXEC_HOST\" 2> /dev/null".format(masterID)
    bjobsout = subprocess.check_output(command, universal_newlines=True, shell=True)
    for outline in bjobsout.splitlines():
        outline = outline.split()
        try:
            driverhost = outline[2].split('*')[1]
        except:
            driverhost = None
        driverdict = {'jobid':outline[0], 'status':outline[1], 'host':driverhost}
        drivers.append(driverdict)
    return drivers

def launch(runtime):
    if not os.path.exists(os.path.expanduser('~/sparklogs')):
        os.mkdir(os.path.expanduser('~/sparklogs'))
    
    sparktype = args.version
    masterjobID = startmaster(sparktype, runtime)
    time.sleep(5)
    try:
        for i in range(args.nnodes):
            startworker(sparktype, masterjobID, runtime)
    except:
        print("Worker launch failed")
        traceback.print_exc()
        sys.exit(1)
    return masterjobID

def startmaster(sparktype, runtime):
    options = ''
    if runtime is not None:
        options = "-W {}".format(runtime)
    if args.lsf_project is not None: 
        options += ' -P {}'.format(args.lsf_project)
    try:
        #bsub requires argument for command, but the esub replaces it automatically
        command = "bsub -q spark32 -a \"spark32(master,{})\" {} commandstring".format(sparktype,options)
        print(command)
        rawout = subprocess.check_output(command, universal_newlines=True, shell=True)
        masterjobID = rawout.split(" ")[1].lstrip("<").rstrip(">")
    except:
        print("Master launch failed.")
        traceback.print_exc()
        sys.exit(1)
    print("Master submitted. Job ID is {}".format(masterjobID))
    return masterjobID

def startworker(sparktype, masterjobID, runtime):
    masterURL = None
    masterURL = getmasterbyjobID(masterjobID)
    while masterURL is None:
        masterURL = getmasterbyjobID(masterjobID)
        if masterURL is None: 
            if not args.silentlaunch:
                waitformaster = input("No master with the job id {} running. Do you want to wait for it to start? (y/n) ".format(masterjobID))
                if waitformaster == 'n':
                    print("Master may be orphaned. Please check your submitted jobs.")
                    sys.exit(0)
            time.sleep(60)
    options = ''
    if runtime is not None:
        options = "-W {}".format(runtime)
    if args.lsf_project is not None: 
        options += ' -P {}'.format(args.lsf_project)
    try: 
        command = "bsub -q spark32 -a \"spark32(worker,{})\" -J W{} {} commandstring".format(sparktype,masterjobID, options)
        print(command)
        rawout = subprocess.check_output(command, universal_newlines=True, shell=True)
        workerjobID = rawout.split(" ")[1].lstrip("<").rstrip(">")
        print(("Worker submitted. Job ID is {}".format(workerjobID)))
    except:
        print("Worker launch failed.")
        traceback.print_exc()
        
def getenvironment():
    #Set MASTER
    if "MASTER" not in os.environ:
        print("MASTER not found")
        masterlist = getallmasters()
        masterjobID = selectionlist(masterlist,'master')
        masterhost = getmasterbyjobID(masterjobID)
        if '*' in masterhost: 
            masterhost = masterhost.split('*')[1]
        os.environ["MASTER"] = str("spark://{}:7077".format(masterhost))
    else:
        print("MASTER found {}".format(os.getenv('MASTER')))
        masterhost = os.getenv('MASTER').replace("spark://","").replace(":7077","")
        if '*' in masterhost: 
            masterhost = masterhost.split('*')[1]
            
    #Set SPARK_HOME
    if "SPARK_HOME" not in os.environ:
        versout = subprocess.check_output("bjobs -noheader -o 'COMMAND' -r -m {}".format(masterhost), universal_newlines=True, shell=True)
        verspath = SPARKVERSIONS[versout.split()[1]]
        os.environ["SPARK_HOME"] = str(verspath) 

    #Set PATH
    sparkpath = "{}/bin:{}/sbin".format(os.getenv('SPARK_HOME'), os.getenv('SPARK_HOME')) 
    if sparkpath not in os.environ['PATH']:
        os.environ["PATH"] = str("{}/bin:{}".format(sparkpath, os.environ['PATH']))

def checkslots(nodeslots=default_node_slots):
    if nodeslots == default_node_slots:
        options = "{} {}".format(default_node_slots, default_options)
    elif nodeslots == alt_slots:
        options = "{} {}".format(alt_slots, alt_options)
    else: 
        options = "{} {}".format(nodeslots, nonfull_options)
    return options

def submit(jobID, nodeslots, sparkcommand, runtime):
    getenvironment()
    options = "-n {} -W {}".format(checkslots(nodeslots), runtime)
    if args.driveroutfile is not '':
        options += ' -o {}'.format(args.driveroutfile)
    if args.lsf_project is not None:
        options += ' -P {}'.format(args.lsf_project)
    if args.driveronspark:
        options += ' -q spark-drivers'
    try:
        command = "bsub {} -J D{} \"{}\"".format(options, jobID, sparkcommand) 
        print(command)
        rawout = subprocess.check_output(command, universal_newlines=True, shell=True)
        driverJobID = rawout.split(" ")[1].lstrip("<").rstrip(">")
        print('Driver submitted. Job ID is {}'.format(driverJobID))
    except:
        print("Driver failed to launch. Cluster is still running.")
        traceback.print_exc()
        sys.exit(1)
    return driverJobID

def destroy(jobID):
    if jobID is '':
        print("Please specify a job ID for a master or cluster to tear it down.")
        sys.exit()
    else:
        bkilljob(jobID)
        workers = []
        workers = getworkersbymasterID(jobID)
        if workers:
            for worker in workers:
                bkilljob(worker['jobid'])
        drivers = []
        drivers = getdriversbymasterID(jobID)
        if drivers:
            for driver in drivers:
                bkilljob(driver['jobid'])

def launchAndWait():
    jobID  = launch(args.hard_runtime)
    master = None     
    while master is None:
        master = getmasterbyjobID(jobID)
        if master is not None:
            break
        time.sleep(60) # wait 60 seconds to avoid spamming the cluster
        sys.stdout.write('.')
        sys.stdout.flush()
    os.environ["MASTER"] = "spark://{}:7077".format(master)
    enoughworkers = False
    while enoughworkers == False:
        time.sleep(60)
        workerlist = getworkersbymasterID(jobID)
        rworkercount = len([worker for worker in  workerlist if worker['status'] == 'RUN'])
        if rworkercount is None:
            rworkercount = 0
        print('There are {} workers running.'.format(rworkercount))
        if rworkercount >= args.minworkers:
            print('Sufficient workers')
            enoughworkers = True

    return master, jobID

def submitAndDestroy(jobID, driverslots, sparksubargs, runtime):
    master=getmasterbyjobID(jobID)
    os.environ["MASTER"] = "spark://{}:7077".format(master)
    driverjobID = submit(jobID, driverslots, sparksubargs, runtime)
    drivercomplete = False
    while not drivercomplete:
        driverstat = subprocess.check_output("bjobs -noheader -o 'STAT' {}".format(driverjobID), universal_newlines=True, shell=True)
        if str(driverstat).rstrip() in ("EXIT", "DONE"):
            drivercomplete = True
        time.sleep(30)
    destroy(jobID)

def bkilljob(jobID):
    command = "bkill {}".format(jobID)
    num_tries = 3
    for i in range(num_tries):
        try:
            bkillout = subprocess.check_output(command, universal_newlines=True, shell=True)
            print(bkillout)
            break
        except:
            print("Failed to kill job {}:".format(jobID))
            traceback.print_exc()
            time.sleep(5)

def selectionlist(joblist, jobtype):
    i = 0
    selectlist = {}
    if len(joblist) == 1:
        jobID = joblist[0]['jobid']
        return jobID
    else:
        print("Select {} from list below:".format(jobtype))
        for job in joblist:
            i = i + 1
            selectlist[i] = job['jobid']
            print("{}) Host: {} jobID: {} Status: {}".format(i, job['host'], job['jobid'], job['status']))
        while True:
            selection = int(input("Selection? "))
            if selection <= i:
                jobID = selectlist[selection]
                skipcheckstop = True
                break
            else:
                print("Invalid selection.")
        return jobID

if __name__ == "__main__":

    SPARKVERSIONS = {'2.3.1': '/misc/local/spark-2.3.1'}

    skipcheckstop = False
    parser = argparse.ArgumentParser(description="launch spark cluster job")
                        
    choices = ('lsd')
                        
    parser.add_argument("task", choices=choices)
    parser.add_argument("-n", "--nnodes", type=int, default=2, required=False)
    parser.add_argument("-v", "--version", type=str, default=defaultversion, required=False)
    parser.add_argument("-t", "--hard_runtime", type=str, default=default_runlimit, required=False)
    parser.add_argument("-s", "--submitargs", type=str, default='', required=False)
    parser.add_argument("-o", "--driveroutfile", type=str, default='', required=False)
    parser.add_argument("-d", "--driverslots", type=int, default=default_node_slots, required=False)
    parser.add_argument("-P", "--lsf_project", type=str, default=None, required=False)
    parser.add_argument("--driveronspark", action="store_true")
    parser.add_argument("--silentlaunch", action="store_true")
    parser.add_argument("--minworkers", type=int, default=1, required=False)
                        
    args = parser.parse_args()
                        
    if args.task == 'lsd':
        master, jobID = launchAndWait()
        master = 'spark://%s:7077' % master
        sparksubargs = 'spark-submit {}'.format(args.submitargs)
        print('\n')     
        print(('%-20s%s\n%-20s%s' % ( 'job id:', jobID, 'spark master:', master ) ))
        print('\n')     
        p = multiprocessing.Process(target=submitAndDestroy, args=(jobID, args.driverslots, sparksubargs,args.hard_runtime))
        p.start()       
